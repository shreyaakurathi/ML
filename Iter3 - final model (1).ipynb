{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90533329",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import csr_matrix\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from fuzzywuzzy import fuzz\n",
    "\n",
    "from surprise import SVD, SVDpp, KNNBasic\n",
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate,train_test_split, GridSearchCV\n",
    "from surprise import NormalPredictor\n",
    "from surprise import Reader\n",
    "\n",
    "import re \n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "754d563b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\shrey\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "56c20972",
   "metadata": {},
   "outputs": [],
   "source": [
    "movies = pd.read_csv(r'C:\\Users\\shrey\\OneDrive\\Desktop\\ML\\ml-latest-small\\movies.csv')\n",
    "ratings = pd.read_csv(r'C:\\Users\\shrey\\OneDrive\\Desktop\\ML\\ml-latest-small\\ratings.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17bc7879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.  5.  3.  2.  1.  4.5 3.5 2.5 0.5 1.5]\n"
     ]
    }
   ],
   "source": [
    "ratings_array= ratings['rating'].unique()\n",
    "max_rating = np.amax(ratings_array)\n",
    "min_rating = np.amin(ratings_array)\n",
    "print(ratings_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "165d79eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_map = pd.Series(movies.movieId.values,index=movies.title).to_dict()\n",
    "reverse_movie_map = {v: k for k, v in movie_map.items()}\n",
    "movieId_to_index_map = pd.Series(movies.index.values,index=movies.movieId).to_dict()\n",
    "movieId_all_array = movies['movieId'].unique()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d37c963",
   "metadata": {},
   "source": [
    "To get movie id that corresponds to the movie name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ccf45ba4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_movieId (movie_name):\n",
    "    if (movie_name in movie_map):\n",
    "        return movie_map[movie_name]\n",
    "    else:\n",
    "        similar = []\n",
    "        for title, movie_id in movie_map.items():\n",
    "            ratio = fuzz.ratio(title.lower(), movie_name.lower())\n",
    "            if ( ratio >= 60):\n",
    "                similar.append( (title, movie_id, ratio ) )\n",
    "        if (len(similar) == 0):\n",
    "            print(\"Movie does not exist\")\n",
    "        else:\n",
    "            match_item = sorted( similar , key=lambda x: x[2] )[::-1]\n",
    "            print( \"Matched item might be:\", match_item[0][0], \", ratio=\",match_item[0][2] )\n",
    "            return match_item[0][1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5364b1",
   "metadata": {},
   "source": [
    "# 3. Content Based Filtering "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06998a6a",
   "metadata": {},
   "source": [
    "Content-based filtering uses item features to recommend other items similar to what the user likes, based on their previous actions or explicit feedback."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd4cb74",
   "metadata": {},
   "source": [
    "Here i will be using the TF-IDF pairwise approach in vector space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7c501817",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(text):\n",
    "    torkenized = [PorterStemmer().stem(word).lower() for word in text.split('|') if word not in stopwords.words('english')]\n",
    "    return torkenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "37461f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfid=TfidfVectorizer(analyzer='word', tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70635037",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_matrix = tfid.fit_transform(movies['genres'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a45b9ca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cos_sim = cosine_similarity(tfidf_matrix,tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "132dc360",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9742, 20)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8a458ebe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9742, 9742)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cos_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba3c5b3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9742, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "183ae75c",
   "metadata": {},
   "source": [
    "# 4. Collaborative Filtering - using svd model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f06f9dd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "features = ['userId','movieId', 'rating']\n",
    "reader = Reader(rating_scale=(min_rating, max_rating))\n",
    "data = Dataset.load_from_df(ratings[features], reader)\n",
    "param_grid = {'n_epochs': [5, 10], 'lr_all': [0.002, 0.005],\n",
    "              'reg_all': [0.4, 0.6]}\n",
    "gs = GridSearchCV(SVD, param_grid, measures=['rmse', 'mae'], cv=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3694c7bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "gs.fit(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ff4c5fd3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.89401538724907"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_score['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f8974631",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'n_epochs': 10, 'lr_all': 0.005, 'reg_all': 0.4}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.best_params['rmse']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bfc5d1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<surprise.prediction_algorithms.matrix_factorization.SVD at 0x285a3478190>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_params = gs.best_params['rmse']\n",
    "model_svd = gs.best_estimator['rmse']\n",
    "model_svd.fit(data.build_full_trainset())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8c6af5df",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rating_from_prediction(prediction, ratings_array):\n",
    "    rating = ratings_array[np.argmin([np.abs(item-prediction)for item in ratings_array])]\n",
    "    return rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a08e621a",
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = model_svd.predict(1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "76ba5f12",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rating 0    4.0\n",
      "Name: rating, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print('rating',ratings[(ratings.userId==1)&(ratings.movieId==1)]['rating'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "63bbb27e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction 4.380136368781048\n"
     ]
    }
   ],
   "source": [
    "print(\"prediction\",prediction.est)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab249d75",
   "metadata": {},
   "source": [
    "# Build hyrbid! "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a50d8e",
   "metadata": {},
   "source": [
    "# First i'll be building an item based fn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8dc6fe7",
   "metadata": {},
   "source": [
    "It will return the top n (10) movie recommendation based on the input movie\n",
    "\n",
    "The parameters of the function are:\n",
    "\n",
    " similarity_matrix: pairwise similarity matrix [ 2D ]\n",
    "\n",
    " movieId_all_array:array of all movie Ids [1D]\n",
    "\n",
    " ratings_data: ratings data\n",
    "\n",
    " id_to_movie_map: the map from movieId to movie title\n",
    "\n",
    " movieId_to_index_map: the map from movieId to the index of the movie dataframe\n",
    "\n",
    " inp_movie_list: input list of movies\n",
    "\n",
    " n_recommendations: top n recommendations\n",
    "\n",
    " userId: int optional (default=-99), the user Id\n",
    "            if userId = -99, the new user will be created\n",
    "            if userId = -1, the latest inserted user is chosen\n",
    "\n",
    "    Return:\n",
    "    list of top n movie recommendations\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5d05e4c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recommendation_item_based( similarity_matrix ,movieId_all_array, ratings_data, id_to_movie_map, movieId_to_index_map, inp_movie_list, n_recommendations, userId=-99):\n",
    "\n",
    "    if (userId == -99):\n",
    "        userId = np.amax( ratings_data['userId'].unique() ) + 1\n",
    "    elif (userId == -1):\n",
    "        userId = np.amax( ratings_data['userId'].unique() )\n",
    "\n",
    "    movieId_list = []\n",
    "    for movie_name in inp_movie_list:\n",
    "        movieId_list.append( get_movieId(movie_name) )    \n",
    "\n",
    "    # Get the movie id which corresponding to the movie the user didn't watch before\n",
    "    movieId_user_exist = list( ratings_data[ ratings_data.userId==userId ]['movieId'].unique() )\n",
    "    movieId_user_exist = movieId_user_exist + movieId_list\n",
    "    movieId_input = []\n",
    "    for movieId in movieId_all_array:\n",
    "        if (movieId not in movieId_user_exist):\n",
    "            movieId_input.append( movieId )\n",
    "\n",
    "\n",
    "    index = movieId_to_index_map[movieId_list[0]]\n",
    "    cos_sim_scores=list(enumerate(similarity_matrix[index]))\n",
    "    cos_sim_scores=sorted(cos_sim_scores,key=lambda x:x[1],reverse=True)\n",
    "    \n",
    "    topn_movieIndex = []\n",
    "    icount = 0\n",
    "    for i in range(len(cos_sim_scores)):\n",
    "        if( cos_sim_scores[i][0] in [movieId_to_index_map[ids] for ids in movieId_input ]  ):\n",
    "            icount += 1\n",
    "            topn_movieIndex.append( cos_sim_scores[i][0] )\n",
    "        if( icount == n_recommendations ):\n",
    "            break\n",
    "    \n",
    "    topn_movie = [ movies.loc[index].title for index in topn_movieIndex ]\n",
    "    return topn_movie\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9e1600",
   "metadata": {},
   "source": [
    "# User based fn is next"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524acb7d",
   "metadata": {},
   "source": [
    "It will return top n (10) movie recommendation based on input movie\n",
    "The parameters are:\n",
    "    \n",
    "best_model_params: dict, {'iterations': iter, 'rank': rank, 'lambda_': reg}\n",
    "\n",
    " movieId_all_array: the array of all movie Id\n",
    "\n",
    "ratings_data: ratings data\n",
    "\n",
    " id_to_movie_map: the map from movieId to movie title\n",
    "\n",
    " inp_movie_list: list, user's list of favorite movies\n",
    "\n",
    "n_recommendations: int, top n recommendations\n",
    "\n",
    "userId: int optional (default=-99), the user Id\n",
    "            if userId = -99, the new user will be created\n",
    "            if userId = -1, the latest inserted user is chosen\n",
    "\n",
    "    Return:\n",
    "    list of top n movie recommendations\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "350af84d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_recommendation_user_based(best_model_params, movieId_all_array, ratings_data, id_to_movie_map,inp_movie_list, n_recommendations, userId=-99 ):\n",
    "\n",
    "\n",
    "    movieId_list = []\n",
    "    for movie_name in inp_movie_list:\n",
    "        movieId_list.append( get_movieId(movie_name) )\n",
    "\n",
    "    if (userId == -99):\n",
    "        userId = np.amax( ratings_data['userId'].unique() ) + 1\n",
    "    elif (userId == -1):\n",
    "        userId = np.amax( ratings_data['userId'].unique() )\n",
    "\n",
    "    ratings_array = ratings['rating'].unique()\n",
    "    max_rating = np.amax( ratings_array )\n",
    "    min_rating = np.amin( ratings_array )\n",
    "    \n",
    "    # create the new row which corresponds to the input data\n",
    "    user_rows = [[userId, movieId, max_rating] for movieId in movieId_list]\n",
    "    df = pd.DataFrame(user_rows, columns =['userId', 'movieId', 'rating']) \n",
    "    train_data = pd.concat([ratings_data, df], ignore_index=True, sort=False)\n",
    "\n",
    "    # Get the movie id which corresponding to the movie the user didn't watch before\n",
    "    movieId_user_exist = train_data[ train_data.userId==userId ]['movieId'].unique()\n",
    "    movieId_input = []\n",
    "    for movieId in movieId_all_array:\n",
    "        if (movieId not in movieId_user_exist):\n",
    "            movieId_input.append( movieId )\n",
    "\n",
    "    reader = Reader(rating_scale=(min_rating, max_rating))\n",
    "\n",
    "    data = Dataset.load_from_df(train_data, reader)\n",
    "\n",
    "    model = SVD(**best_model_params)\n",
    "    model.fit(data.build_full_trainset())\n",
    "\n",
    "    predictions = []\n",
    "    for movieId in movieId_input:\n",
    "        predictions.append( model.predict(userId,movieId) )\n",
    "\n",
    "    \n",
    "    sort_index = sorted(range(len(predictions)), key=lambda k: predictions[k].est, reverse=True)\n",
    "    topn_predictions = [ predictions[i].est for i in sort_index[0:min(n_recommendations,len(predictions))] ]\n",
    "    topn_movieIds = [ movieId_input[i] for i in sort_index[0:min(n_recommendations,len(predictions))] ]\n",
    "    topn_rating = [ get_rating_from_prediction( pre, ratings_array ) for pre in topn_predictions ]\n",
    "\n",
    "    topn_movie = [ id_to_movie_map[ ids ] for ids in topn_movieIds ]\n",
    "    return topn_movie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6c6d4a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommendation(fav):\n",
    "    # get recommendations\n",
    "    n_recommendations = 10\n",
    "\n",
    "    recommends_item_based = make_recommendation_item_based( \n",
    "        similarity_matrix = cos_sim,\n",
    "        movieId_all_array = movieId_all_array,\n",
    "        ratings_data = ratings[features], \n",
    "        id_to_movie_map = reverse_movie_map, \n",
    "        movieId_to_index_map = movieId_to_index_map,\n",
    "        inp_movie_list = inp, \n",
    "        n_recommendations = n_recommendations)\n",
    "\n",
    "    recommends_user_based = make_recommendation_user_based(\n",
    "        best_model_params = best_params, \n",
    "        movieId_all_array = movieId_all_array,\n",
    "        ratings_data = ratings[features], \n",
    "        id_to_movie_map = reverse_movie_map, \n",
    "        inp_movie_list = inp, \n",
    "        n_recommendations = n_recommendations)\n",
    "\n",
    "    print(\"Based on items content similarity\")\n",
    "    print('The movies similar to' , inp , ':' )\n",
    "    for i, title in enumerate(recommends_item_based):\n",
    "        print(i+1, title)  \n",
    "    if( len(recommends_item_based) < n_recommendations ):\n",
    "      print(\"Couldn't offer recommendations :(\")    \n",
    "\n",
    "    print(\"Based on similarity between users\")\n",
    "    print('The users like' , inp, 'also like:')\n",
    "    for i, title in enumerate(recommends_user_based):\n",
    "        print(i+1, title)\n",
    "    if( len(recommends_user_based) < n_recommendations ):\n",
    "      print(\"Couldn't offer recommendations :(\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "af51feab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched item might be: American Pie (1999) , ratio= 77\n",
      "Matched item might be: American Pie (1999) , ratio= 77\n",
      "Based on items content similarity\n",
      "The movies similar to ['American pie'] :\n",
      "1 Grumpier Old Men (1995)\n",
      "2 Sabrina (1995)\n",
      "3 Clueless (1995)\n",
      "4 Two if by Sea (1996)\n",
      "5 French Twist (Gazon maudit) (1995)\n",
      "6 If Lucy Fell (1996)\n",
      "7 Boomerang (1992)\n",
      "8 Pie in the Sky (1996)\n",
      "9 Mallrats (1995)\n",
      "10 Nine Months (1995)\n",
      "Based on similarity between users\n",
      "The users like ['American pie'] also like:\n",
      "1 Shawshank Redemption, The (1994)\n",
      "2 Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)\n",
      "3 Streetcar Named Desire, A (1951)\n",
      "4 Godfather, The (1972)\n",
      "5 Lawrence of Arabia (1962)\n",
      "6 Fight Club (1999)\n",
      "7 Three Billboards Outside Ebbing, Missouri (2017)\n",
      "8 Pulp Fiction (1994)\n",
      "9 Rear Window (1954)\n",
      "10 Usual Suspects, The (1995)\n"
     ]
    }
   ],
   "source": [
    "inp= ['American pie']\n",
    "recommendation(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9122eb97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d0a22ab7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matched item might be: Father of the Bride Part II (1995) , ratio= 90\n",
      "Matched item might be: Father of the Bride Part II (1995) , ratio= 90\n",
      "Based on items content similarity\n",
      "The movies similar to ['Father of the bride part II '] :\n",
      "1 Four Rooms (1995)\n",
      "2 Ace Ventura: When Nature Calls (1995)\n",
      "3 Bio-Dome (1996)\n",
      "4 Friday (1995)\n",
      "5 Black Sheep (1996)\n",
      "6 Mr. Wrong (1996)\n",
      "7 Happy Gilmore (1996)\n",
      "8 Steal Big, Steal Little (1995)\n",
      "9 Flirting With Disaster (1996)\n",
      "10 Down Periscope (1996)\n",
      "Based on similarity between users\n",
      "The users like ['Father of the bride part II '] also like:\n",
      "1 Shawshank Redemption, The (1994)\n",
      "2 Dr. Strangelove or: How I Learned to Stop Worrying and Love the Bomb (1964)\n",
      "3 Philadelphia Story, The (1940)\n",
      "4 Lawrence of Arabia (1962)\n",
      "5 Rear Window (1954)\n",
      "6 Godfather, The (1972)\n",
      "7 Little Big Man (1970)\n",
      "8 Brazil (1985)\n",
      "9 Fight Club (1999)\n",
      "10 Celebration, The (Festen) (1998)\n"
     ]
    }
   ],
   "source": [
    "inp= ['Father of the bride part II ']\n",
    "recommendation(inp)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79d53a67",
   "metadata": {},
   "source": [
    "In my previous notebook i have analysed the coldstart problem and split my dataset into testing and training.\n",
    "This is my 3rd iteration of my model - in Phase 1 i had outlined a rough approach that involves using KNN, but after multiple tries i have settled on SVD to be my models best fit "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08388060",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Create a Pickle file using serialization \n",
    "import pickle\n",
    "pickle_out = open(\"classifier.pkl\",\"wb\")\n",
    "pickle.dump(classifier, pickle_out)\n",
    "pickle_out.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
